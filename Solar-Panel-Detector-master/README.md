# Solar Panel Detector â€“ EcoIdeathon 2026 Submission

## How to Run the Pipeline

### 1. Install requirements
pip install -r environment/requirements.txt

### 2. Prepare input file
Create input.xlsx in project root with columns:

- sample_id
- latitude
- longitude

### 3. Run
python pipeline/main.py

### 4. Outputs
- predictions/*.json â†’ Required JSON output
- artifacts/*_image.jpg â†’ Satellite images downloaded

## Pipeline Structure
- pipeline/main.py â†’ Main execution script
- pipeline/detector.py â†’ YOLO model loader + inference
- pipeline/image_fetcher.py â†’ Satellite image download
- pipeline/output_builder.py â†’ JSON output builder

## Model
Place your YOLO model in /model/best.pt




Solar-Panel-Detector ğŸ›°ï¸â˜€ï¸
==============================
![](https://raw.githubusercontent.com/ArielDrabkin/Solar-Panel-Detector/master/deployment/examples/spd-demo.gif)

--------

## Overview

The Solar-Panel-Detector is an innovative AI-driven tool designed to identify solar panels in satellite imagery.  
Utilizing the state-of-the-art YOLOv8 object-detection model and various cutting-edge technologies, this project
demonstrates how AI can be leveraged for environmental sustainability.   
  
Try the application [here](https://huggingface.co/spaces/ArielDrabkin/Solar-Panel-Detector)
or you can run it locally by following the instructions below.

--------

## Project Organization

    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ models             <- Trained and serialized models
    â”‚Â Â  â””â”€â”€ copy_paste-augmentation.pt     
    â”‚Â Â  â””â”€â”€ final-mosaic-augmentation.pt  
    â”‚Â Â  â””â”€â”€ mixup-augmentation.pt          
    â”‚Â Â  â””â”€â”€ mosaic-and-mixup-0.8-0.2-augmentation.pt     
    â”‚Â Â  â””â”€â”€ mosaic-augmentation.pt 
    â”‚Â Â  â””â”€â”€ NO-augmentation.pt
    â”œâ”€â”€ notebooks          <- Jupyter notebooks.
    â”‚Â Â  â””â”€â”€ Error Analysis.ipynb
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚Â Â  â””â”€â”€ final model training results        <- Generated graphics and figures to be used in reporting
    â”œâ”€â”€ src             <- Source code for various stages of the project
    â”‚Â Â  â””â”€â”€ retrive_satellite_imgae.py        <- Script for obtaining satellite image for a given address
    â”‚Â Â  â””â”€â”€ Predict.py                        <- Script for predicting with the trained model on a given image
    â”‚Â Â  â””â”€â”€ main.py                            <- Script for running the application
    â”œâ”€â”€ training            <- Training code for the several experiments made and the final model training.
    â”‚Â Â  â””â”€â”€ copy_paste-augmentation-training.ipynb
    â”‚Â Â  â””â”€â”€ final-mosaic-augmentation-training.ipynb
    â”‚Â Â  â””â”€â”€ mixup-augmentation-training.ipynb
    â”‚Â Â  â””â”€â”€ mosaic-and-mixup-0.8-0.2-augmentation-training.ipynb     
    â”‚Â Â  â””â”€â”€ mosaic-augmentation-training.ipynb
    â”‚Â Â  â””â”€â”€ NO-augmentation-training.ipynb
    â”œâ”€â”€ deployment               <- Deployment code for the application as it was dep;oyed on Hugging Face Spaces.
    â”‚Â Â  â””â”€â”€ examples       <- Examples of images for the application use.
    â”‚Â Â  â””â”€â”€ README.md          <- The HuggingFace Space built-in README for developers using this project.
    â”‚Â Â  â””â”€â”€ detector.pt        <- The trained model for the application.
    â”‚Â Â  â””â”€â”€ requirements.txt   <- The requirements file for deploying the application.
    â”‚Â Â  â””â”€â”€ SolarPanelDetector.py   <- The script that holds the functionality of the application.
    â”‚Â Â  â””â”€â”€ app.py   <- The script that runs the application.
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”œâ”€â”€ secret               <- Secterkeys for use in this project (No Keys present).

--------

## Key Technologies

**Roboflow** ğŸ¤–: For data organization and preprocessing.  
**Ultralytics** ğŸŒŠ: Utilizing their open-source YOLOv8 model for accurate object detection.  
**Google Colab** â™¾ï¸: For model training and evaluation.  
**Lightning AI**âš¡: Enhancing training efficiency.  
**ClearML** ğŸ“‰: For training management and performance analysis.  
**Google Maps API** ğŸ—ºï¸: To acquire satellite imagery.  
**Gradio** ğŸ¢: Creating a user-friendly GUI.  
**Hugging Face Spaces** ğŸ¤—: For deploying the application.

--------

## Application

* The Solar-Panel-Detector app analyzes satellite images to detect the presence of solar panels, serving both
  environmental research and the solar energy market.
* It provides insights into potential areas for solar panel installation and aids in understanding the spread of solar
  energy usage.
* The Predictions can be made on a specific address or a given image.

If you would like to use the app with the deployed GUI you can visit:
https://huggingface.co/spaces/ArielDrabkin/Solar-Panel-Detector

--------

## Usage

To run the solar panel detector locally -

1. clone the repository with the following command:

``` 
git clone https://github.com/ArielDrabkin/Solar-Panel-Detector.git
```

2. Install the required packages with the following command:

```
pip install -r requirements.txt
```

3. The script can be executed with several command-line arguments:

* -k, --api_key: (Optional) Your API key for mapping services.
* -a, --address: (Optional) Address for prediction.
* -z, --zoom: (Optional) Image Zoom level, default is 19.
* -i, --image_dir: (Optional) Directory of images for applying predictions.
* Once you are predicting on an address the predicted image will show up and automatically be saved in the "src" folder.

4. To predict on an address, first you will need to get a Google Maps API key
   at https://developers.google.com/maps/documentation/maps-static/get-api-key.

5. **Predicting Using Address Only:**  
   To get predictions based on an address, first update your Google Maps API key in the "secret.json" file.  
   Then use the -a or --address argument:

```
python main.py --address "1600 Pennsylvania Avenue NW, Washington, United States"
```

6. **Predicting Using a Custom API Key:**  
   Alternatively, if you have a custom API key and wish to use it instead of the one in ../secret.json, use the -k or
   --api_key argument:

```
python main.py --api_key "YOUR_CUSTOM_API_KEY" --address "1600 Pennsylvania Avenue NW, Washington, United States"
```

7. **Adjusting Zoom Level:**
   Zoom level is set to 19 by default, but can be adjusted according to your needs. For more information visit https://developers.google.com/maps/documentation/maps-static/start#Zoomlevels.  
   To adjust the zoom level of the image, use the -z or --zoom argument:

```
python main.py --address "1600 Pennsylvania Avenue NW, Washington, United States" --zoom 18
```

8. **Predicting with Image Analysis:**  
   To perform image analysis on a specific image, ensure that the specified directory contains the image you want to
   analyze.
   use the -i or --image_dir argument:

```
python main.py --image_dir "/path/to/image/directory"
```

9. **Predict and Enjoy!**

![](https://media2.giphy.com/media/l5D4Zr95KJdUd1E7jt/200.gif?cid=82a1493bvrrr37gb80ycpjqds92n6ybwud9ebiebre854ocw&ep=v1_gifs_related&rid=200.gif&ct=g)

--------

## Training

For using the data-set:

1. Get a secret key from roboflow where the data is stored.
2. Update the secret.json file or the direct code with your key.
3. Run the following code:

```
# Load the data sets from roboflow
with open("secret.json") as file:
    roboflow_api_key = json.load(file)["roboflow_api_key"]
rf = Roboflow(api_key=roboflow_api_key)
project = rf.workspace("ariel-drabkin-tifqg").project("solar-panel-detector-imvoh")
dataset = project.version(1).download("yolov8")
```

--------

## References

--------

## Aknowledgements

--------
<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
